# -*- coding: utf-8 -*-
"""frachackbeyond.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ox15rmgIUGC9xUxH3CPOe3K73Y09DOde
"""

# --- Colab Cell 1: Setup and Library Imports ---

# Import all necessary libraries for the entire workflow upfront for robustness
import tensorflow as tf
from tensorflow.keras.models import load_model, Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import BatchNormalization, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from PIL import Image
import numpy as np
import os
import kagglehub
from google.colab import files
from IPython.display import display, HTML

# Define constants needed globally
IMG_SIZE = (224, 224)

print("TensorFlow Version:", tf.__version__)
print("Setup complete. Libraries imported.")

# --- Colab Cell 2: Data Download and Inspection ---

# 1. Install the required Kaggle Hub library
!pip install -q kagglehub

# 2. Download the NEW dataset
# *** NEW DATASET: pkdarabi/bone-break-classification-image-dataset ***
print("Starting NEW dataset download: pkdarabi/bone-break-classification-image-dataset")
path_to_dataset = kagglehub.dataset_download("pkdarabi/bone-break-classification-image-dataset")

# The path returned is the root of the downloaded files.
BASE_DATA_DIR = path_to_dataset
print(f"Path to downloaded dataset files: {BASE_DATA_DIR}")

# 3. Inspect the contents to find the classification folders (e.g., 'train', 'test', 'Normal', 'Fractured')
print("\nDirectory contents (Top 1 level):")
# Use os.listdir for a simple, flat list of files/folders in the root download directory
contents = os.listdir(BASE_DATA_DIR)
for item in contents:
    path = os.path.join(BASE_DATA_DIR, item)
    if os.path.isdir(path):
        print(f"  [DIR] {item}/")
    else:
        print(f"  [FILE] {item}")

# Set the base directory to the root for an initial attempt.
# We may need to adjust TRAIN_VAL_BASE_DIR in the next step based on the output.
TRAIN_VAL_BASE_DIR = BASE_DATA_DIR

# --- Colab Diagnostics: Find Deepest Class Folders ---

import os

# This path is based on your last training attempt, adding one level of nesting:
# Previous path: /.../Bone Break Classification
# New path is nested one level deeper to find the class folders.
DEEP_PATH = '/root/.cache/kagglehub/datasets/pkdarabi/bone-break-classification-image-dataset/versions/4/Bone Break Classification/Bone Break Classification'

print(f"Listing contents of the deeply nested path: {DEEP_PATH}")
# List the contents of the suspected training folder. This should show the 'Normal' and 'Fractured' folders.
!ls -F "{DEEP_PATH}"

# --- Colab Cell 3: Train and Save Model ---

# NOTE: ALL necessary imports were performed in Step 1.

# Get the dataset path (assumed to be cached from Step 2)
path_to_dataset = kagglehub.dataset_download("pkdarabi/bone-break-classification-image-dataset")

# *** PATH CORRECTION APPLIED ***
# Based on the inspection output, the classification folders are inside this subdirectory:
TRAIN_VAL_BASE_DIR = os.path.join(path_to_dataset, 'Bone Break Classification')

# Define training parameters
IMAGE_WIDTH = 224
IMAGE_HEIGHT = 224
BATCH_SIZE = 32
EPOCHS = 20
VALIDATION_SPLIT = 0.2

# 1. Data Augmentation and Generators
train_datagen = ImageDataGenerator(
    rescale=1./255, rotation_range=15, width_shift_range=0.1,
    height_shift_range=0.1, shear_range=0.1, zoom_range=0.1,
    horizontal_flip=True, validation_split=VALIDATION_SPLIT
)
val_datagen = ImageDataGenerator(
    rescale=1./255, validation_split=VALIDATION_SPLIT
)

print(f"Using corrected base directory for data: {TRAIN_VAL_BASE_DIR}")
print("Preparing Training Data Generator...")
train_generator = train_datagen.flow_from_directory(
    TRAIN_VAL_BASE_DIR, target_size=(IMAGE_WIDTH, IMAGE_HEIGHT), batch_size=BATCH_SIZE,
    class_mode='binary', subset='training', seed=42, color_mode='rgb'
)
print("Preparing Validation Data Generator...")
validation_generator = val_datagen.flow_from_directory(
    TRAIN_VAL_BASE_DIR, target_size=(IMAGE_WIDTH, IMAGE_HEIGHT), batch_size=BATCH_SIZE,
    class_mode='binary', subset='validation', seed=42, color_mode='rgb'
)

# 2. Define the RepoScan Custom CNN Model
def build_reposcan_model(input_shape):
    #
    model = Sequential([
        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape), BatchNormalization(), MaxPooling2D((2, 2)),
        Conv2D(64, (3, 3), activation='relu'), BatchNormalization(), MaxPooling2D((2, 2)),
        Conv2D(128, (3, 3), activation='relu'), BatchNormalization(), MaxPooling2D((2, 2)), Dropout(0.3),
        Flatten(),
        Dense(128, activation='relu'), Dropout(0.5),
        Dense(1, activation='sigmoid')
    ])
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    return model

# Build and summarize the model
input_shape = (IMAGE_WIDTH, IMAGE_HEIGHT, 3)
reposcan_model = build_reposcan_model(input_shape)

callbacks = [
    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),
    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.00001)
]
print("\nRepoScan Model Summary:")
reposcan_model.summary()

# 3. Train the model
print("\nStarting Model Training...")
try:
    history = reposcan_model.fit(
        train_generator,
        steps_per_epoch=train_generator.samples // BATCH_SIZE, epochs=EPOCHS,
        validation_data=validation_generator,
        validation_steps=validation_generator.samples // BATCH_SIZE, callbacks=callbacks
    )
    # 4. Save the trained model
    FINAL_MODEL_FILENAME = 'reposcan_fracture_model_trained.h5'
    reposcan_model.save(FINAL_MODEL_FILENAME)
    print(f"\n‚úÖ Model training complete. Model saved as: {FINAL_MODEL_FILENAME}")
except Exception as e:
    print(f"Error during model fitting: {e}")
    print("‚ùå Model not saved due to training error. Check if 2 classes were found.")

# --- Colab Cell 4: Load Model and Run Prediction UI (MULTI-CLASS) ---
# This loads the model and launches the interactive test interface.

# NOTE: ALL necessary imports were performed in Step 1.
#this is where the actucal model work and this should be treated as the prototype of the xray detection model.
#this woud only worked to analys the fracture or physical injuries
from tensorflow.keras.models import load_model, Sequential
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from PIL import Image # For opening images
import numpy as np # For prediction analysis
import os # For file operations
from google.colab import files # For upload widget
from IPython.display import display, HTML # For displaying results
import kagglehub # For dynamic path check

# --- Global Constants (Defined from Step 1) ---
IMG_SIZE = (224, 224)
MODEL_PATH = '/content/reposcan_fracture_model_trained_multi.h5' # Using the trained multi-class model name

# --- Dynamic Class Name Determination ---
# This ensures the label names (10 fracture types) match the folder names used in training.
path_to_dataset = kagglehub.dataset_download("pkdarabi/bone-break-classification-image-dataset")
# *** CORRECTED PATH ***
TRAIN_VAL_BASE_DIR = os.path.join(path_to_dataset, 'Bone Break Classification', 'Bone Break Classification')

dummy_datagen = ImageDataGenerator(rescale=1./255)
try:
    dummy_generator = dummy_datagen.flow_from_directory(
        TRAIN_VAL_BASE_DIR, target_size=IMG_SIZE, class_mode='categorical', batch_size=1, shuffle=False
    )
    # Get the list of class names in the correct index order
    CLASS_NAMES = list(dummy_generator.class_indices.keys())
    CLASS_NAMES.sort() # Ensure alphabetical order matches Keras's internal sorting

    print(f"Dynamically set CLASS_NAMES ({len(CLASS_NAMES)} total): {CLASS_NAMES}")
except Exception as e:
    print(f"Error determining multi-classes dynamically ({e}). Using fallback.")
    CLASS_NAMES = ['Unknown Fracture Type']

# --- Model Loading Functions ---
def create_placeholder_model():
    # If the file fails to load, create a placeholder model structure
    print("WARNING: Using a dummy model. Please check logs for previous training errors.")
    model = Sequential([
        Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)),
        MaxPooling2D((2, 2)), Flatten(), Dense(len(CLASS_NAMES), activation='softmax')
    ])
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    return model

try:
    if os.path.exists(MODEL_PATH):
        model = load_model(MODEL_PATH)
        print(f"‚úÖ Success: Loaded trained MULTI-CLASS model from {MODEL_PATH}")
    else:
        model = create_placeholder_model()
        print("Multi-Class Model file not found. Created placeholder model.")
except Exception as e:
    print(f"Error loading model: {e}")
    model = create_placeholder_model()
    print("Continuing with placeholder model.")

# --- Prediction Logic Functions ---
def preprocess_image(image_path):
    # Loads, resizes, and normalizes the image
    try:
        img = Image.open(image_path).convert('RGB')
        img = img.resize(IMG_SIZE)
        img_array = np.expand_dims(np.array(img) / 255.0, axis=0)
        return img_array
    except Exception as e:
        print(f"Error during image preprocessing: {e}")
        return None

def predict_fracture(model, preprocessed_image):
    # Runs inference and formats result for multi-class prediction
    if preprocessed_image is None: return "Prediction failed."

    # Predict probabilities for all 10 classes
    predictions = model.predict(preprocessed_image)[0]

    # Find the index and probability of the top prediction
    predicted_index = np.argmax(predictions)
    confidence = predictions[predicted_index]

    # Get the class name
    label = CLASS_NAMES[predicted_index]

    if 'fracture' in label.lower():
        color_class = "text-red-600 font-bold"
        status_icon = "üö®"
    else:
        color_class = "text-yellow-600 font-bold"
        status_icon = "‚ö†Ô∏è"

    result_html = f"""
    <div style="font-family: Arial; padding: 15px; border: 1px solid #ccc; border-radius: 8px; max-width: 400px; margin: 20px auto;">
        <h3 style="font-size: 1.5em; margin-bottom: 10px;">RepoScan Prediction Result (Multi-Class)</h3>
        <p style="font-size: 1.2em;">{status_icon} **Type Detected:** <span class="{color_class}">{label}</span></p>
        <p>Confidence: **{confidence:.2f}**</p>
        <hr style="margin-top: 10px; margin-bottom: 10px;">
        <p style="font-size: 0.9em; color: #555;">*Note: This model detects 10 types of bone fractures.*</p>
        <p style="font-size: 0.9em; color: #555;">*Disclaimer: This is an AI prototype. Always consult a licensed professional.*</p>
    </div>
    """
    return result_html

def run_reposcan():
    global model
    if 'model' not in globals():
        print("Error: The 'model' variable is not defined.")
        return

    print("Please upload an X-ray image (PNG or JPG) now to test RepoScan:")
    uploaded = files.upload()

    if not uploaded:
        print("No file uploaded. Aborting prediction.")
        return

    for filename in uploaded.keys():
        temp_path = f"/content/{filename}"
        with open(temp_path, 'wb') as f:
            f.write(uploaded[filename])

        print(f"\nProcessing uploaded file: {filename}")
        image_array = preprocess_image(temp_path)
        result_html = predict_fracture(model, image_array)

        display(HTML(f'<h4 style="margin-top: 20px;">Uploaded X-ray: {filename}</h4>'))
        img_display = Image.open(temp_path)
        display(img_display)
        display(HTML(result_html))

        os.remove(temp_path)

# --- Run the main prediction loop ---
run_reposcan()